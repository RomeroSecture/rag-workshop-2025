{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ RAG Workshop 2025 - Bienvenida\n",
    "\n",
    "## De Cero a ProducciÃ³n en 8 Horas\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ‘‹ Â¡Bienvenido al Workshop!\n",
    "\n",
    "En las prÃ³ximas 8 horas vas a:\n",
    "- ğŸ¯ Entender quÃ© es RAG y por quÃ© es fundamental\n",
    "- ğŸ› ï¸ Construir tu propio sistema RAG desde cero\n",
    "- âš¡ Optimizar para reducir latencia un 75%\n",
    "- ğŸš€ Desplegar en producciÃ³n\n",
    "- ğŸ’¡ Aplicar RAG a un caso real\n",
    "\n",
    "### ğŸ“‹ Agenda del DÃ­a\n",
    "\n",
    "| Hora | MÃ³dulo | Objetivo |\n",
    "|------|--------|----------|\n",
    "| 08:00-08:15 | Apertura | Setup y contexto |\n",
    "| 08:15-09:30 | **MÃ³dulo 1** | Fundamentos RAG |\n",
    "| 09:30-09:45 | â˜• Break | Networking |\n",
    "| 09:45-11:15 | **MÃ³dulo 2** | Arquitectura y OptimizaciÃ³n |\n",
    "| 11:15-12:00 | ğŸ• Almuerzo | Recargar energÃ­a |\n",
    "| 12:00-13:30 | **MÃ³dulo 3** | Frameworks Avanzados |\n",
    "| 13:30-13:45 | â˜• Break | Stretch |\n",
    "| 13:45-15:00 | **MÃ³dulo 4** | ProducciÃ³n |\n",
    "| 15:00-15:45 | **Proyecto** | Tu propio RAG |\n",
    "| 15:45-16:00 | Cierre | Q&A y siguientes pasos |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ VerificaciÃ³n del Ambiente\n",
    "\n",
    "Ejecuta las siguientes celdas para verificar que todo estÃ¡ configurado correctamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 1: Verificar importaciones bÃ¡sicas\n",
    "print(\"ğŸ” Verificando instalaciÃ³n...\\n\")\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# AÃ±adir src al path\n",
    "sys.path.append(str(Path.cwd().parent / 'src'))\n",
    "\n",
    "# Verificar Python\n",
    "print(f\"âœ… Python {sys.version.split()[0]}\")\n",
    "\n",
    "# Verificar librerÃ­as principales\n",
    "try:\n",
    "    import openai\n",
    "    print(f\"âœ… OpenAI {openai.__version__}\")\n",
    "except:\n",
    "    print(\"âŒ OpenAI no instalado\")\n",
    "\n",
    "try:\n",
    "    import chromadb\n",
    "    print(f\"âœ… ChromaDB {chromadb.__version__}\")\n",
    "except:\n",
    "    print(\"âŒ ChromaDB no instalado\")\n",
    "\n",
    "try:\n",
    "    import langchain\n",
    "    print(f\"âœ… LangChain {langchain.__version__}\")\n",
    "except:\n",
    "    print(\"âŒ LangChain no instalado\")\n",
    "\n",
    "try:\n",
    "    import llama_index\n",
    "    print(f\"âœ… LlamaIndex {llama_index.__version__}\")\n",
    "except:\n",
    "    print(\"âŒ LlamaIndex no instalado\")\n",
    "\n",
    "print(\"\\nâœ¨ Ambiente verificado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2: Verificar API Key\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Cargar variables de entorno\n",
    "load_dotenv()\n",
    "\n",
    "# Verificar API Key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if api_key and api_key.startswith(\"sk-\"):\n",
    "    print(\"âœ… API Key configurada correctamente\")\n",
    "    print(f\"   Primeros caracteres: {api_key[:7]}...\")\n",
    "else:\n",
    "    print(\"âŒ API Key no configurada\")\n",
    "    print(\"\\nğŸ“ Por favor:\")\n",
    "    print(\"1. Abre el archivo .env\")\n",
    "    print(\"2. AÃ±ade tu API key: OPENAI_API_KEY=sk-...\")\n",
    "    print(\"3. Guarda el archivo\")\n",
    "    print(\"4. Ejecuta esta celda de nuevo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 3: Test de conexiÃ³n con OpenAI\n",
    "from openai import OpenAI\n",
    "\n",
    "try:\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    \n",
    "    # Test simple\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": \"Di 'RAG Workshop Ready!' en 5 palabras\"}],\n",
    "        max_tokens=20\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… ConexiÃ³n con OpenAI exitosa!\")\n",
    "    print(f\"\\nğŸ¤– Respuesta: {response.choices[0].message.content}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error conectando con OpenAI: {e}\")\n",
    "    print(\"\\nğŸ”§ Posibles soluciones:\")\n",
    "    print(\"- Verifica que tu API key es vÃ¡lida\")\n",
    "    print(\"- Verifica que tienes crÃ©ditos en tu cuenta\")\n",
    "    print(\"- Verifica tu conexiÃ³n a internet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ El Problema: LLMs Sin Contexto\n",
    "\n",
    "Veamos por quÃ© necesitamos RAG con un ejemplo real:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 4: DemostraciÃ³n del problema\n",
    "print(\"ğŸ” EXPERIMENTO: LLM sin contexto empresarial\\n\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Pregunta sobre datos especÃ­ficos de la empresa\n",
    "pregunta = \"Â¿CuÃ¡ntos dÃ­as de vacaciones tienen los empleados en nuestra empresa?\"\n",
    "\n",
    "print(f\"ğŸ“ Pregunta: {pregunta}\\n\")\n",
    "\n",
    "# Sin RAG - El modelo no tiene contexto\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": pregunta}]\n",
    ")\n",
    "\n",
    "print(\"âŒ Respuesta SIN RAG:\")\n",
    "print(\"-\"*40)\n",
    "print(response.choices[0].message.content)\n",
    "print(\"\\nâš ï¸ Nota: El modelo no tiene informaciÃ³n especÃ­fica de tu empresa!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 5: Preview de la soluciÃ³n con RAG\n",
    "print(\"âœ¨ PREVIEW: La misma pregunta CON RAG\\n\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Simulamos contexto recuperado\n",
    "contexto = \"\"\"\n",
    "Del Manual del Empleado (pÃ¡gina 47):\n",
    "- Empleados nuevos (0-5 aÃ±os): 22 dÃ­as hÃ¡biles\n",
    "- Empleados senior (5-10 aÃ±os): 25 dÃ­as hÃ¡biles  \n",
    "- Empleados veteran (10+ aÃ±os): 30 dÃ­as hÃ¡biles\n",
    "- DÃ­as adicionales por antigÃ¼edad cada 5 aÃ±os\n",
    "- Posibilidad de comprar hasta 5 dÃ­as extra\n",
    "\"\"\"\n",
    "\n",
    "# Con RAG - Proporcionamos contexto\n",
    "prompt_con_rag = f\"\"\"\n",
    "Contexto relevante:\n",
    "{contexto}\n",
    "\n",
    "Pregunta: {pregunta}\n",
    "\n",
    "Responde basÃ¡ndote ÃšNICAMENTE en el contexto proporcionado.\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt_con_rag}]\n",
    ")\n",
    "\n",
    "print(\"âœ… Respuesta CON RAG:\")\n",
    "print(\"-\"*40)\n",
    "print(response.choices[0].message.content)\n",
    "print(\"\\nğŸ¯ Â¡Esto es lo que construiremos hoy!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š MÃ©tricas que Vamos a Optimizar\n",
    "\n",
    "Durante el dÃ­a, mejoraremos estas mÃ©tricas progresivamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6: Visualizar objetivos de mejora\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Datos de evoluciÃ³n\n",
    "modules = ['MÃ³dulo 1\\n(BÃ¡sico)', 'MÃ³dulo 2\\n(Optimizado)', 'MÃ³dulo 3\\n(Avanzado)', 'MÃ³dulo 4\\n(ProducciÃ³n)']\n",
    "latency = [2000, 1000, 800, 500]  # ms\n",
    "cost = [0.010, 0.008, 0.006, 0.004]  # USD\n",
    "accuracy = [70, 80, 85, 90]  # %\n",
    "\n",
    "# Crear grÃ¡ficos\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Latencia\n",
    "ax1.bar(modules, latency, color=['red', 'orange', 'yellow', 'green'])\n",
    "ax1.set_ylabel('Latencia (ms)')\n",
    "ax1.set_title('â±ï¸ ReducciÃ³n de Latencia')\n",
    "ax1.set_ylim(0, 2500)\n",
    "for i, v in enumerate(latency):\n",
    "    ax1.text(i, v + 50, str(v), ha='center')\n",
    "\n",
    "# Costo\n",
    "ax2.bar(modules, cost, color=['red', 'orange', 'yellow', 'green'])\n",
    "ax2.set_ylabel('Costo por query (USD)')\n",
    "ax2.set_title('ğŸ’° ReducciÃ³n de Costos')\n",
    "ax2.set_ylim(0, 0.012)\n",
    "for i, v in enumerate(cost):\n",
    "    ax2.text(i, v + 0.0003, f'${v:.3f}', ha='center')\n",
    "\n",
    "# Accuracy\n",
    "ax3.bar(modules, accuracy, color=['red', 'orange', 'yellow', 'green'])\n",
    "ax3.set_ylabel('Accuracy (%)')\n",
    "ax3.set_title('ğŸ¯ Mejora en PrecisiÃ³n')\n",
    "ax3.set_ylim(0, 100)\n",
    "for i, v in enumerate(accuracy):\n",
    "    ax3.text(i, v + 1, f'{v}%', ha='center')\n",
    "\n",
    "plt.suptitle('ğŸš€ EvoluciÃ³n de MÃ©tricas Durante el Workshop', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ“ˆ Mejoras que lograremos:\")\n",
    "print(f\"- Latencia: {((latency[0]-latency[-1])/latency[0]*100):.0f}% mÃ¡s rÃ¡pido\")\n",
    "print(f\"- Costo: {((cost[0]-cost[-1])/cost[0]*100):.0f}% mÃ¡s barato\")\n",
    "print(f\"- Accuracy: {accuracy[-1]-accuracy[0]}% mÃ¡s preciso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ Tu Kit de Herramientas\n",
    "\n",
    "Durante el workshop usaremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 7: Explorar estructura del proyecto\n",
    "print(\"ğŸ“ ESTRUCTURA DEL PROYECTO\\n\")\n",
    "print(\"rag-workshop-2025/\")\n",
    "print(\"â”‚\")\n",
    "print(\"â”œâ”€â”€ ğŸ““ notebooks/          # Tus notebooks de trabajo\")\n",
    "print(\"â”‚   â”œâ”€â”€ 00_inicio.ipynb   # â† EstÃ¡s aquÃ­\")\n",
    "print(\"â”‚   â”œâ”€â”€ 01_fundamentos.ipynb\")\n",
    "print(\"â”‚   â”œâ”€â”€ 02_arquitectura.ipynb\")\n",
    "print(\"â”‚   â”œâ”€â”€ 03_frameworks.ipynb\")\n",
    "print(\"â”‚   â”œâ”€â”€ 04_produccion.ipynb\")\n",
    "print(\"â”‚   â””â”€â”€ 05_proyecto_final.ipynb\")\n",
    "print(\"â”‚\")\n",
    "print(\"â”œâ”€â”€ ğŸ“¦ src/               # CÃ³digo modular\")\n",
    "print(\"â”‚   â”œâ”€â”€ shared_config.py  # ConfiguraciÃ³n compartida\")\n",
    "print(\"â”‚   â”œâ”€â”€ module_1_basics.py\")\n",
    "print(\"â”‚   â”œâ”€â”€ module_2_optimized.py\")\n",
    "print(\"â”‚   â”œâ”€â”€ module_3_advanced.py\")\n",
    "print(\"â”‚   â””â”€â”€ module_4_production.py\")\n",
    "print(\"â”‚\")\n",
    "print(\"â”œâ”€â”€ ğŸ“Š data/              # Documentos de prueba\")\n",
    "print(\"â”‚   â”œâ”€â”€ company_handbook.pdf\")\n",
    "print(\"â”‚   â”œâ”€â”€ technical_docs.pdf\")\n",
    "print(\"â”‚   â””â”€â”€ faqs.json\")\n",
    "print(\"â”‚\")\n",
    "print(\"â””â”€â”€ ğŸ”§ .env              # Tu configuraciÃ³n (API keys)\")\n",
    "\n",
    "print(\"\\nâœ… Todo listo para empezar!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¡ Tips para el Workshop\n",
    "\n",
    "### ğŸ¯ Para aprovechar al mÃ¡ximo:\n",
    "\n",
    "1. **Experimenta sin miedo** - Los errores son aprendizaje\n",
    "2. **Pregunta todo** - No hay preguntas tontas\n",
    "3. **Toma notas** - Especialmente de los \"aha moments\"\n",
    "4. **Comparte descubrimientos** - Todos aprendemos de todos\n",
    "5. **Piensa en tu caso de uso** - Â¿DÃ³nde aplicarÃ­as RAG?\n",
    "\n",
    "### âŒ¨ï¸ Atajos Ãºtiles en Jupyter:\n",
    "\n",
    "- `Shift + Enter` - Ejecutar celda y avanzar\n",
    "- `Ctrl + Enter` - Ejecutar celda sin avanzar\n",
    "- `Tab` - Autocompletar\n",
    "- `Shift + Tab` - Ver documentaciÃ³n\n",
    "- `Esc + B` - Insertar celda abajo\n",
    "- `Esc + DD` - Eliminar celda\n",
    "\n",
    "### ğŸ”— Enlaces rÃ¡pidos:\n",
    "\n",
    "- [DocumentaciÃ³n OpenAI](https://platform.openai.com/docs)\n",
    "- [LangChain Docs](https://python.langchain.com/)\n",
    "- [LlamaIndex Docs](https://docs.llamaindex.ai/)\n",
    "- [Canal Slack del Workshop](#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Â¡Listos para Empezar!\n",
    "\n",
    "### Siguiente paso:\n",
    "ğŸ‘‰ Abre el notebook **`01_fundamentos.ipynb`** para comenzar con el MÃ³dulo 1\n",
    "\n",
    "---\n",
    "\n",
    "**Â¡Vamos a construir algo increÃ­ble!** ğŸ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}