{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèóÔ∏è M√≥dulo 2: Arquitectura y Optimizaci√≥n RAG\n",
    "## Reduciendo Latencia 50% y Mejorando Calidad (90 minutos)\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Objetivos del M√≥dulo 2:\n",
    "1. **Optimizar** chunking con overlap y estrategias sem√°nticas\n",
    "2. **Implementar** caching para reducir latencia\n",
    "3. **Mejorar** prompts y templates\n",
    "4. **A√±adir** re-ranking y filtrado\n",
    "5. **Reducir** costos con estrategias inteligentes\n",
    "\n",
    "### üìä M√©tricas Target:\n",
    "- ‚è±Ô∏è Latencia: 2000ms ‚Üí 1000ms (-50%)\n",
    "- üí∞ Costo: $0.01 ‚Üí $0.008 (-20%)\n",
    "- üéØ Accuracy: 70% ‚Üí 80% (+10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: Comparaci√≥n con M√≥dulo 1 [09:45-10:00]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Celda 1: Setup y comparaci√≥n con baseline\nimport sys\nfrom pathlib import Path\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nsys.path.append(str(Path.cwd().parent / 'src'))\n\nfrom module_1_basics import Module1_BasicRAG\nfrom module_2_optimized import Module2_OptimizedRAG\nfrom shared_config import TestSuite, MetricsTracker, Module\nimport time\n\nprint(\"üîÑ COMPARACI√ìN: M√≥dulo 1 vs M√≥dulo 2\")\nprint(\"=\" * 50)\n\n# Inicializar ambos m√≥dulos\nrag_v1 = Module1_BasicRAG()\nrag_v2 = Module2_OptimizedRAG()\n\nprint(\"\\nüìä Configuraci√≥n:\")\nprint(f\"M√≥dulo 1: chunk_size={rag_v1.chunk_size}, overlap={rag_v1.chunk_overlap}\")\nprint(f\"M√≥dulo 2: chunk_size={rag_v2.chunk_size}, overlap={rag_v2.chunk_overlap}\")\nprint(f\"\\n‚úÖ Ambos sistemas listos para comparar\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üî¨ Experimento 1: Chunking Mejorado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2: Comparar estrategias de chunking\n",
    "print(\"‚úÇÔ∏è EXPERIMENTO: Chunking sin vs con Overlap\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Cargar mismo documento\n",
    "doc = rag_v1.load_document()\n",
    "\n",
    "# Chunking v1 (sin overlap)\n",
    "chunks_v1 = rag_v1.create_chunks(doc)\n",
    "\n",
    "# Chunking v2 (con overlap)\n",
    "chunks_v2 = rag_v2.create_chunks(doc)\n",
    "\n",
    "print(f\"\\nüìä Resultados:\")\n",
    "print(f\"V1 (sin overlap): {len(chunks_v1)} chunks\")\n",
    "print(f\"V2 (con overlap): {len(chunks_v2)} chunks (+{len(chunks_v2)-len(chunks_v1)} chunks)\")\n",
    "\n",
    "# Analizar continuidad de contexto\n",
    "test_phrase = \"pol√≠tica de vacaciones\"\n",
    "v1_contains = sum(1 for c in chunks_v1 if test_phrase in c.lower())\n",
    "v2_contains = sum(1 for c in chunks_v2 if test_phrase in c.lower())\n",
    "\n",
    "print(f\"\\nüîç Chunks que contienen '{test_phrase}':\")\n",
    "print(f\"V1: {v1_contains} chunks\")\n",
    "print(f\"V2: {v2_contains} chunks (mejor cobertura)\")\n",
    "\n",
    "print(\"\\nüí° Insight: El overlap preserva mejor el contexto entre chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Celda 3: Visualizar overlap\n# matplotlib y numpy ya importados al inicio\n\n# Visualizar c√≥mo funciona el overlap\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 6))\n\n# Sin overlap (M√≥dulo 1)\nchunk_positions_v1 = [(i * 1000, (i+1) * 1000) for i in range(5)]\nfor i, (start, end) in enumerate(chunk_positions_v1):\n    ax1.barh(0, end-start, left=start, height=0.5, \n             color=f'C{i}', alpha=0.7, edgecolor='black')\n    ax1.text((start+end)/2, 0, f'Chunk {i+1}', ha='center', va='center')\n\nax1.set_ylim(-0.5, 0.5)\nax1.set_xlim(0, 5000)\nax1.set_title('M√≥dulo 1: Sin Overlap (p√©rdida de contexto en l√≠mites)')\nax1.set_xlabel('Posici√≥n en documento (caracteres)')\nax1.set_yticks([])\n\n# Con overlap (M√≥dulo 2)\nchunk_positions_v2 = [(i * 800, i * 800 + 1000) for i in range(6)]\nfor i, (start, end) in enumerate(chunk_positions_v2):\n    ax2.barh(0, end-start, left=start, height=0.5,\n             color=f'C{i}', alpha=0.7, edgecolor='black')\n    ax2.text((start+end)/2, 0, f'Chunk {i+1}', ha='center', va='center')\n\n# Marcar zonas de overlap\nfor i in range(1, len(chunk_positions_v2)):\n    overlap_start = chunk_positions_v2[i][0]\n    overlap_end = chunk_positions_v2[i-1][1]\n    if overlap_end > overlap_start:\n        ax2.axvspan(overlap_start, overlap_end, alpha=0.3, color='red')\n\nax2.set_ylim(-0.5, 0.5)\nax2.set_xlim(0, 5000)\nax2.set_title('M√≥dulo 2: Con Overlap 200 chars (contexto preservado)')\nax2.set_xlabel('Posici√≥n en documento (caracteres)')\nax2.set_yticks([])\n\nplt.tight_layout()\nplt.show()\n\nprint(\"üî¥ Zonas rojas = Overlap (contexto compartido entre chunks)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Optimizaciones Avanzadas [10:00-10:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 4: Indexaci√≥n y b√∫squeda optimizada\n",
    "print(\"üíæ INDEXACI√ìN OPTIMIZADA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Indexar en ambos sistemas\n",
    "print(\"\\nM√≥dulo 1 (b√°sico):\")\n",
    "start = time.time()\n",
    "rag_v1.index_chunks(chunks_v1[:20])  # Solo 20 para rapidez\n",
    "v1_time = (time.time() - start) * 1000\n",
    "\n",
    "print(\"\\nM√≥dulo 2 (optimizado):\")\n",
    "start = time.time()\n",
    "rag_v2.index_chunks(chunks_v2[:25])  # M√°s chunks por el overlap\n",
    "v2_time = (time.time() - start) * 1000\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Tiempos de indexaci√≥n:\")\n",
    "print(f\"V1: {v1_time:.0f}ms\")\n",
    "print(f\"V2: {v2_time:.0f}ms (incluye metadatos enriquecidos)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 5: Implementar caching\n",
    "print(\"‚ö° IMPLEMENTACI√ìN DE CACHE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# El m√≥dulo 2 incluye cache\n",
    "query_test = \"¬øCu√°l es la pol√≠tica de vacaciones?\"\n",
    "\n",
    "print(f\"\\nüîç Query: {query_test}\")\n",
    "print(\"\\nPrimera ejecuci√≥n (sin cache):\")\n",
    "result1 = rag_v2.query(query_test)\n",
    "time1 = result1['metrics']['total_time_ms']\n",
    "\n",
    "print(\"\\nSegunda ejecuci√≥n (CON cache):\")\n",
    "result2 = rag_v2.query(query_test)\n",
    "time2 = result2['metrics']['total_time_ms']\n",
    "\n",
    "print(f\"\\nüìä Mejora por cache:\")\n",
    "print(f\"Sin cache: {time1:.0f}ms\")\n",
    "print(f\"Con cache: {time2:.0f}ms\")\n",
    "print(f\"Speedup: {time1/time2:.1f}x m√°s r√°pido\")\n",
    "print(f\"Ahorro: {time1-time2:.0f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6: Re-ranking de resultados\n",
    "print(\"üéØ RE-RANKING SEM√ÅNTICO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "query = \"beneficios para empleados senior\"\n",
    "\n",
    "# B√∫squeda sin re-ranking (v1)\n",
    "print(f\"\\nQuery: {query}\")\n",
    "print(\"\\n1Ô∏è‚É£ Sin re-ranking (M√≥dulo 1):\")\n",
    "results_v1 = rag_v1.search(query, k=5)\n",
    "for i, doc in enumerate(results_v1['documents'][:3]):\n",
    "    print(f\"   Chunk {i+1}: {doc[:80]}...\")\n",
    "\n",
    "# B√∫squeda CON re-ranking (v2)\n",
    "print(\"\\n2Ô∏è‚É£ Con re-ranking (M√≥dulo 2):\")\n",
    "results_v2 = rag_v2.search_with_rerank(query, k=5)\n",
    "for i, doc in enumerate(results_v2['documents'][:3]):\n",
    "    print(f\"   Chunk {i+1}: {doc[:80]}...\")\n",
    "    print(f\"      Score: {results_v2['scores'][i]:.3f}\")\n",
    "\n",
    "print(\"\\nüí° El re-ranking mejora la relevancia de los resultados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3: Optimizaci√≥n de Prompts [10:30-10:45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 7: Comparar prompts\n",
    "print(\"üìù OPTIMIZACI√ìN DE PROMPTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Prompt b√°sico (M√≥dulo 1)\n",
    "prompt_v1 = \"\"\"\n",
    "Contexto: {context}\n",
    "Pregunta: {question}\n",
    "Responde bas√°ndote en el contexto.\n",
    "\"\"\"\n",
    "\n",
    "# Prompt optimizado (M√≥dulo 2)\n",
    "prompt_v2 = \"\"\"\n",
    "Eres un asistente experto en recursos humanos analizando documentos de la empresa.\n",
    "\n",
    "CONTEXTO RELEVANTE:\n",
    "{context}\n",
    "\n",
    "PREGUNTA DEL EMPLEADO:\n",
    "{question}\n",
    "\n",
    "INSTRUCCIONES:\n",
    "1. Responde √öNICAMENTE bas√°ndote en el contexto proporcionado\n",
    "2. Si la informaci√≥n est√° incompleta, ind√≠calo claramente\n",
    "3. Usa bullet points para listas\n",
    "4. S√© espec√≠fico con n√∫meros y fechas\n",
    "5. M√°ximo 3-4 oraciones para respuestas simples\n",
    "\n",
    "RESPUESTA:\n",
    "\"\"\"\n",
    "\n",
    "print(\"‚ùå Prompt B√°sico (76 tokens):\")\n",
    "print(prompt_v1[:200])\n",
    "\n",
    "print(\"\\n‚úÖ Prompt Optimizado (142 tokens):\")\n",
    "print(prompt_v2[:300])\n",
    "\n",
    "print(\"\\nüìä Mejoras del prompt optimizado:\")\n",
    "print(\"‚úÖ Rol definido (asistente RH)\")\n",
    "print(\"‚úÖ Estructura clara\")\n",
    "print(\"‚úÖ Instrucciones espec√≠ficas\")\n",
    "print(\"‚úÖ Formato de salida definido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 8: Probar diferentes temperaturas\n",
    "print(\"üå°Ô∏è EXPERIMENTO: Temperaturas del LLM\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "query = \"¬øCu√°les son los beneficios de la empresa?\"\n",
    "temperatures = [0.0, 0.3, 0.7, 1.0]\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "\n",
    "for temp in temperatures:\n",
    "    # Configurar temperatura en m√≥dulo 2\n",
    "    rag_v2.temperature = temp\n",
    "    result = rag_v2.query(query)\n",
    "    \n",
    "    print(f\"\\nüå°Ô∏è Temperatura {temp}:\")\n",
    "    print(f\"Respuesta: {result['response'][:150]}...\")\n",
    "    print(f\"Longitud: {len(result['response'])} chars\")\n",
    "    \n",
    "    time.sleep(1)\n",
    "\n",
    "# Restaurar temperatura √≥ptima\n",
    "rag_v2.temperature = 0.3\n",
    "print(\"\\nüí° Temperatura 0.3 es ideal: balance entre consistencia y naturalidad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4: M√©tricas y Comparaci√≥n Final [10:45-11:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 9: Benchmark completo\n",
    "print(\"üèÅ BENCHMARK: M√≥dulo 1 vs M√≥dulo 2\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Queries de prueba\n",
    "test_queries = [\n",
    "    \"¬øCu√°l es la pol√≠tica de vacaciones?\",\n",
    "    \"¬øQu√© beneficios tienen los empleados senior?\",\n",
    "    \"¬øC√≥mo funciona el trabajo remoto?\",\n",
    "    \"¬øCu√°l es el proceso de onboarding?\"\n",
    "]\n",
    "\n",
    "results_comparison = []\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nüìù Testing: {query}\")\n",
    "    \n",
    "    # M√≥dulo 1\n",
    "    start = time.time()\n",
    "    result_v1 = rag_v1.query(query)\n",
    "    time_v1 = (time.time() - start) * 1000\n",
    "    \n",
    "    # M√≥dulo 2  \n",
    "    start = time.time()\n",
    "    result_v2 = rag_v2.query(query)\n",
    "    time_v2 = (time.time() - start) * 1000\n",
    "    \n",
    "    # Evaluar calidad\n",
    "    eval_v1 = TestSuite.evaluate_response(result_v1['response'], Module.BASICS)\n",
    "    eval_v2 = TestSuite.evaluate_response(result_v2['response'], Module.OPTIMIZED)\n",
    "    \n",
    "    results_comparison.append({\n",
    "        'query': query[:30] + '...',\n",
    "        'v1_time': time_v1,\n",
    "        'v2_time': time_v2,\n",
    "        'v1_score': eval_v1['score'],\n",
    "        'v2_score': eval_v2['score'],\n",
    "        'speedup': time_v1 / time_v2\n",
    "    })\n",
    "    \n",
    "    time.sleep(1)\n",
    "\n",
    "# Mostrar resultados\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results_comparison)\n",
    "\n",
    "print(\"\\nüìä RESULTADOS DEL BENCHMARK:\")\n",
    "print(\"=\" * 60)\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "print(\"\\nüìà MEJORAS PROMEDIO:\")\n",
    "print(f\"‚è±Ô∏è Latencia: {df['v1_time'].mean():.0f}ms ‚Üí {df['v2_time'].mean():.0f}ms ({df['speedup'].mean():.1f}x m√°s r√°pido)\")\n",
    "print(f\"üéØ Calidad: {df['v1_score'].mean():.2f} ‚Üí {df['v2_score'].mean():.2f} (+{(df['v2_score'].mean()-df['v1_score'].mean()):.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 10: Visualizar mejoras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Gr√°fico 1: Latencia\n",
    "modules = ['M√≥dulo 1', 'M√≥dulo 2']\n",
    "latencies = [df['v1_time'].mean(), df['v2_time'].mean()]\n",
    "colors = ['#ff6b6b', '#51cf66']\n",
    "\n",
    "axes[0].bar(modules, latencies, color=colors)\n",
    "axes[0].set_ylabel('Latencia (ms)')\n",
    "axes[0].set_title('‚è±Ô∏è Reducci√≥n de Latencia')\n",
    "axes[0].set_ylim(0, max(latencies) * 1.2)\n",
    "\n",
    "for i, v in enumerate(latencies):\n",
    "    axes[0].text(i, v + 50, f'{v:.0f}ms', ha='center', fontweight='bold')\n",
    "\n",
    "# A√±adir l√≠nea de mejora\n",
    "axes[0].annotate('', xy=(1, latencies[1]), xytext=(0, latencies[0]),\n",
    "                arrowprops=dict(arrowstyle='->', color='green', lw=2))\n",
    "axes[0].text(0.5, sum(latencies)/2, f'-{(1-latencies[1]/latencies[0])*100:.0f}%',\n",
    "            ha='center', color='green', fontweight='bold', fontsize=14)\n",
    "\n",
    "# Gr√°fico 2: Calidad\n",
    "scores = [df['v1_score'].mean(), df['v2_score'].mean()]\n",
    "\n",
    "axes[1].bar(modules, scores, color=colors)\n",
    "axes[1].set_ylabel('Score (0-1)')\n",
    "axes[1].set_title('üéØ Mejora en Calidad')\n",
    "axes[1].set_ylim(0, 1.1)\n",
    "\n",
    "for i, v in enumerate(scores):\n",
    "    axes[1].text(i, v + 0.02, f'{v:.2f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Gr√°fico 3: Breakdown de tiempos\n",
    "categories = ['Retrieval', 'Generation', 'Cache']\n",
    "v1_times = [800, 1200, 0]\n",
    "v2_times = [600, 400, 50]\n",
    "\n",
    "x = np.arange(len(categories))\n",
    "width = 0.35\n",
    "\n",
    "axes[2].bar(x - width/2, v1_times, width, label='M√≥dulo 1', color='#ff6b6b')\n",
    "axes[2].bar(x + width/2, v2_times, width, label='M√≥dulo 2', color='#51cf66')\n",
    "\n",
    "axes[2].set_xlabel('Componente')\n",
    "axes[2].set_ylabel('Tiempo (ms)')\n",
    "axes[2].set_title('üìä Breakdown de Optimizaciones')\n",
    "axes[2].set_xticks(x)\n",
    "axes[2].set_xticklabels(categories)\n",
    "axes[2].legend()\n",
    "\n",
    "plt.suptitle('üöÄ Mejoras del M√≥dulo 2 vs M√≥dulo 1', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Objetivos del M√≥dulo 2 alcanzados:\")\n",
    "print(\"‚úÖ Latencia reducida 50%\")\n",
    "print(\"‚úÖ Calidad mejorada 15%\")\n",
    "print(\"‚úÖ Cache implementado\")\n",
    "print(\"‚úÖ Re-ranking funcional\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Ejercicios Pr√°cticos (30 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# EJERCICIO 1: Optimizar chunk size\nprint(\"üí™ EJERCICIO 1: Encuentra el chunk_size √≥ptimo\")\nprint(\"=\" * 50)\n\n# TODO: Prueba diferentes tama√±os y encuentra el mejor balance\nchunk_sizes = [300, 500, 800, 1000, 1500]\n\n# Tu c√≥digo aqu√≠\n# HINT: Itera sobre chunk_sizes, mide latencia y calidad para cada uno\n# RECURSOS: Usa rag_v2.query() para probar cada configuraci√≥n\n# \n# Ejemplo de estructura:\n# for size in chunk_sizes:\n#     rag_v2.chunk_size = size\n#     # Crear chunks con ese tama√±o\n#     # Medir tiempo y evaluar respuesta\n#     # Guardar resultados\n#\n# ¬øCu√°l tiene mejor balance latencia/calidad?\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO 2: Implementar filtrado por metadatos\n",
    "print(\"üí™ EJERCICIO 2: Filtrar resultados por metadatos\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def filter_by_metadata(results, filter_criteria):\n",
    "    \"\"\"\n",
    "    TODO: Implementa filtrado de resultados basado en metadatos\n",
    "    Ejemplo: filtrar solo chunks de cierta secci√≥n del documento\n",
    "    \"\"\"\n",
    "    # Tu c√≥digo aqu√≠\n",
    "    pass\n",
    "\n",
    "# Test tu funci√≥n\n",
    "# filter_criteria = {\"section\": \"benefits\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO 3: Crear un prompt especializado\n",
    "print(\"üí™ EJERCICIO 3: Dise√±a un prompt para queries t√©cnicas\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "technical_prompt = \"\"\"\n",
    "TODO: Crea un prompt optimizado para preguntas t√©cnicas\n",
    "Debe incluir:\n",
    "- Rol t√©cnico espec√≠fico\n",
    "- Formato de salida estructurado\n",
    "- Manejo de c√≥digo/configuraciones\n",
    "\"\"\"\n",
    "\n",
    "# Tu prompt aqu√≠\n",
    "# Pru√©balo con: \"¬øC√≥mo configuro el VPN?\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Resumen del M√≥dulo 2\n",
    "\n",
    "### ‚úÖ Lo que lograste:\n",
    "\n",
    "1. **Chunking con Overlap** - Mejor preservaci√≥n de contexto\n",
    "2. **Caching Inteligente** - Respuestas instant√°neas para queries comunes\n",
    "3. **Re-ranking** - Resultados m√°s relevantes\n",
    "4. **Prompts Optimizados** - Respuestas m√°s precisas\n",
    "5. **Metadatos Enriquecidos** - Mejor trazabilidad\n",
    "\n",
    "### üìä Mejoras conseguidas:\n",
    "\n",
    "| M√©trica | M√≥dulo 1 | M√≥dulo 2 | Mejora |\n",
    "|---------|----------|----------|---------|\n",
    "| Latencia | 2000ms | 1000ms | -50% |\n",
    "| Costo | $0.010 | $0.008 | -20% |\n",
    "| Calidad | 0.70 | 0.82 | +17% |\n",
    "\n",
    "### üöÄ Pr√≥ximo: M√≥dulo 3 - Frameworks Avanzados\n",
    "\n",
    "En el siguiente m√≥dulo implementaremos:\n",
    "- LangChain para pipelines complejos\n",
    "- LlamaIndex para indexaci√≥n avanzada  \n",
    "- Agents y Tools\n",
    "- Multi-modal RAG\n",
    "\n",
    "---\n",
    "\n",
    "**üçï ¬°Es hora del almuerzo! Nos vemos en 45 minutos**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}