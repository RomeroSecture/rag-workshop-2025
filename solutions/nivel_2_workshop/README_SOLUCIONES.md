# ðŸ“š Soluciones Completas - Notebook 02: Arquitectura y OptimizaciÃ³n

**Nivel 2: Workshop** - Soluciones esperadas durante el workshop

---

## ðŸ“‹ Ãndice de Soluciones

### âœ… Ejercicios Principales (Celdas 17-19)

| # | Archivo | Celda | DescripciÃ³n | LÃ­neas | Dificultad |
|---|---------|-------|-------------|--------|------------|
| 1 | `02_solucion_ejercicio1.py` | 17 | Optimizar chunk_size | 89 | â­â­ Media |
| 2 | `02_solucion_ejercicio2.py` | 18 | Filtrado por metadata | 83 | â­â­ Media |
| 3 | `02_solucion_ejercicio3.py` | 19 | Prompt especializado tÃ©cnico | 82 | â­â­ Media |
| 4 | `02_solucion_ejercicio4_temperaturas.py` | 8 | Experimentar con temperaturas | 147 | â­â­ Media |

### ðŸ† DesafÃ­os Adicionales (Celda 18 del notebook)

| # | Archivo | DescripciÃ³n | LÃ­neas | Dificultad |
|---|---------|-------------|--------|------------|
| 5 | `02_solucion_desafio_smart_chunking.py` | Chunking inteligente | 289 | â­â­â­ Alta |
| 6 | `02_solucion_desafio_metadata_indexing.py` | IndexaciÃ³n con metadata | 437 | â­â­â­ Alta |
| 7 | `02_solucion_desafio_reranking.py` | Re-ranking avanzado | 394 | â­â­â­ Alta |

**Total**: 7 soluciones completas | 1,331 lÃ­neas de cÃ³digo

---

## ðŸŽ¯ Ejercicio 1: Optimizar chunk_size

**Archivo**: `02_solucion_ejercicio1.py`
**Celda del notebook**: 17
**Tiempo estimado**: 15-20 minutos

### Objetivo
Encontrar el chunk_size Ã³ptimo probando diferentes tamaÃ±os y midiendo el balance entre latencia y calidad.

### Conceptos aprendidos
- âœ… ExperimentaciÃ³n sistemÃ¡tica con parÃ¡metros
- âœ… Trade-offs entre tamaÃ±o de chunk y performance
- âœ… MÃ©tricas combinadas (calidad/latencia)
- âœ… AnÃ¡lisis de resultados con pandas

### Snippet clave
```python
for size in chunk_sizes:
    rag.chunk_size = size
    chunks = rag.create_chunks(doc)

    # Medir latencia y calidad
    times, scores = [], []
    for query in test_queries:
        start = time.time()
        response = rag.query(query)
        times.append((time.time() - start) * 1000)

        eval_result = TestSuite.evaluate_response(response['response'])
        scores.append(eval_result['score'])

    # Score combinado
    combined_score = avg_score / (avg_time / 1000)
```

### Output esperado
```
ðŸ“Š RESULTADOS COMPARATIVOS:
chunk_size  num_chunks  avg_latency_ms  avg_quality  combined_score
300         67          850             0.72         0.847
500         40          920             0.78         0.848
800         25          1050            0.82         0.781  â† Mejor balance
1000        20          1100            0.80         0.727
```

---

## ðŸŽ¯ Ejercicio 2: Filtrado por metadata

**Archivo**: `02_solucion_ejercicio2.py`
**Celda del notebook**: 18
**Tiempo estimado**: 15 minutos

### Objetivo
Implementar funciÃ³n de filtrado de resultados basado en metadata (secciÃ³n, tipo de contenido, etc.)

### Conceptos aprendidos
- âœ… Metadata enriquecidos en vectorDB
- âœ… Filtrado programÃ¡tico de resultados
- âœ… Mejora de precisiÃ³n con filtros
- âœ… Type hints y documentaciÃ³n

### Snippet clave
```python
def filter_by_metadata(results: Dict, filter_criteria: Dict[str, Any]) -> Dict:
    filtered_docs, filtered_metadata, filtered_scores = [], [], []

    for i, metadata in enumerate(results.get('metadatas', [])):
        match = all(
            metadata.get(key) == value
            for key, value in filter_criteria.items()
        )

        if match:
            filtered_docs.append(results['documents'][i])
            filtered_metadata.append(metadata)
            if 'scores' in results:
                filtered_scores.append(results['scores'][i])

    return {
        'documents': filtered_docs,
        'metadatas': filtered_metadata,
        'scores': filtered_scores
    }
```

### Output esperado
```
ðŸ“Š Resultados sin filtro: 10 documentos
ðŸ”§ Aplicando filtro: {"section": "benefits"}
ðŸ“Š Resultados filtrados: 3 documentos

âœ… Top 3 resultados filtrados:
1. Los empleados reciben seguro mÃ©dico completo...
   Metadata: {'section': 'benefits', 'chunk_id': 5}
```

---

## ðŸŽ¯ Ejercicio 3: Prompt especializado tÃ©cnico

**Archivo**: `02_solucion_ejercicio3.py`
**Celda del notebook**: 19
**Tiempo estimado**: 10-15 minutos

### Objetivo
DiseÃ±ar un prompt optimizado para queries tÃ©cnicas con formato estructurado.

### Conceptos aprendidos
- âœ… IngenierÃ­a de prompts
- âœ… DefiniciÃ³n de roles especÃ­ficos
- âœ… Formato de salida estructurado
- âœ… Mejora de calidad de respuestas

### Snippet clave
```python
technical_prompt = """
Eres un especialista en soporte tÃ©cnico IT analizando documentaciÃ³n tÃ©cnica corporativa.

DOCUMENTACIÃ“N RELEVANTE:
{context}

CONSULTA TÃ‰CNICA:
{question}

INSTRUCCIONES:
1. Proporciona SOLO informaciÃ³n basada en la documentaciÃ³n
2. Si requiere configuraciÃ³n, usa formato de cÃ³digo:
   ```
   parÃ¡metro: valor
   ```
3. Incluye advertencias de seguridad si aplica
4. Estructura: Respuesta directa â†’ Pasos â†’ Notas

RESPUESTA TÃ‰CNICA:
"""
```

### Output esperado
```
Query: Â¿CÃ³mo configuro el VPN de la empresa?

Con prompt tÃ©cnico:
âœ… Respuesta estructurada
âœ… Pasos numerados claramente
âœ… CÃ³digo/configuraciÃ³n resaltada
âœ… Advertencias de seguridad incluidas

Con prompt genÃ©rico:
âŒ Respuesta narrativa sin estructura
âŒ Sin diferenciaciÃ³n de cÃ³digo
```

---

## ðŸŽ¯ Ejercicio 4: Experimentar con temperaturas

**Archivo**: `02_solucion_ejercicio4_temperaturas.py`
**Celda del notebook**: 8 (ExperimentaciÃ³n extendida)
**Tiempo estimado**: 20 minutos

### Objetivo
Probar diferentes temperaturas del LLM para encontrar el valor Ã³ptimo para RAG.

### Conceptos aprendidos
- âœ… Impacto de la temperatura en respuestas
- âœ… Balance determinismo vs naturalidad
- âœ… MediciÃ³n de consistencia
- âœ… ConfiguraciÃ³n Ã³ptima para casos de uso

### Snippet clave
```python
temperatures = [0.0, 0.3, 0.5, 0.7, 1.0]

for temp in temperatures:
    rag.temperature = temp

    # Ejecutar misma query mÃºltiples veces
    responses = [rag.query(question) for _ in range(3)]

    # Medir variabilidad
    lengths = [len(r['response']) for r in responses]
    variability = max(lengths) - min(lengths)

    # Word overlap entre respuestas
    words_sets = [set(r['response'][:100].split()) for r in responses]
    overlap = len(words_sets[0] & words_sets[1]) / len(words_sets[0])
```

### Output esperado
```
ðŸŒ¡ï¸ TEMPERATURA: 0.0
   Variabilidad: 0 chars, 100% palabra overlap
   âœ… Perfecto para queries factuales

ðŸŒ¡ï¸ TEMPERATURA: 0.3
   Variabilidad: 15 chars, 95% palabra overlap
   âœ… RECOMENDADO para RAG - Balance ideal

ðŸŒ¡ï¸ TEMPERATURA: 1.0
   Variabilidad: 150 chars, 60% palabra overlap
   âš ï¸  Muy variable - Riesgo de alucinaciones
```

---

## ðŸ† DesafÃ­o 5: Smart Chunking

**Archivo**: `02_solucion_desafio_smart_chunking.py`
**Dificultad**: â­â­â­ Alta
**Tiempo estimado**: 30-40 minutos

### Objetivo
Implementar chunking inteligente que respeta lÃ­mites de frases y pÃ¡rrafos, con overlap.

### TÃ©cnicas avanzadas
- âœ… Regex para detectar lÃ­mites de frases
- âœ… PreservaciÃ³n de contexto con overlap adaptativo
- âœ… Manejo de frases muy largas
- âœ… Algoritmo de ventana deslizante

### Snippet clave
```python
def smart_chunking(text: str, chunk_size: int = 500, overlap: int = 100):
    # Dividir en frases respetando puntuaciÃ³n
    sentence_endings = r'[.!?]\s+|\n\n'
    sentences = re.split(sentence_endings, text)

    chunks = []
    current_chunk = ""
    previous_overlap = ""

    for sentence in sentences:
        if len(current_chunk) + len(sentence) > chunk_size:
            # Guardar chunk con overlap
            full_chunk = previous_overlap + " " + current_chunk
            chunks.append(full_chunk.strip())

            # Calcular overlap para siguiente chunk
            words = current_chunk.split()
            overlap_words = []
            overlap_chars = 0

            for word in reversed(words):
                if overlap_chars + len(word) < overlap:
                    overlap_words.insert(0, word)
                    overlap_chars += len(word) + 1
                else:
                    break

            previous_overlap = " ".join(overlap_words)
            current_chunk = sentence
        else:
            current_chunk += " " + sentence

    return chunks
```

### Beneficios
```
âœ… Preserva significado completo de frases
âœ… Mejora comprensiÃ³n del contexto
âœ… Reduce fragmentaciÃ³n de informaciÃ³n
âœ… Facilita retrieval semÃ¡ntico mÃ¡s preciso

ðŸŽ¯ Ideal para:
   - Documentos tÃ©cnicos con procedimientos
   - Manuales con instrucciones paso a paso
   - FAQs donde cada Q&A es una unidad
```

---

## ðŸ† DesafÃ­o 6: Metadata Enriquecidos

**Archivo**: `02_solucion_desafio_metadata_indexing.py`
**Dificultad**: â­â­â­ Alta
**Tiempo estimado**: 40-50 minutos

### Objetivo
Implementar sistema de metadata enriquecidos para chunks con mÃºltiples seÃ±ales de calidad.

### Metadata implementados
1. **BÃ¡sicos**: chunk_id, source_document, position
2. **Contenido**: length, section, content_type
3. **TÃ©cnicos**: content_hash, indexed_at, version
4. **Calidad**: completeness_score, info_density

### Snippet clave
```python
def extract_metadata_from_chunk(chunk, chunk_id, source_doc, total_chunks):
    metadata = {
        # BÃ¡sicos
        'chunk_id': chunk_id,
        'source_document': Path(source_doc).name,
        'chunk_position': f"{chunk_id + 1}/{total_chunks}",

        # Contenido
        'section': detect_section(chunk),  # benefits, vacation, etc.
        'content_type': detect_content_type(chunk),  # list, table, narrative

        # Calidad
        'completeness_score': calculate_completeness(chunk),  # 0-1
        'info_density': calculate_info_density(chunk),  # 0-1

        # TÃ©cnicos
        'content_hash': hashlib.md5(chunk.encode()).hexdigest(),
        'indexed_at': datetime.now().isoformat(),
    }
    return metadata
```

### Casos de uso
```
1ï¸âƒ£ FILTRADO AVANZADO:
   - Buscar solo en secciÃ³n 'benefits'
   - Excluir chunks con baja info_density
   - Filtrar por tipo de contenido

2ï¸âƒ£ RE-RANKING MEJORADO:
   - Priorizar chunks con alta completeness
   - Boost a secciones especÃ­ficas
   - Penalizar chunks incompletos

3ï¸âƒ£ TRAZABILIDAD:
   - Saber exactamente de dÃ³nde viene info
   - Tracking de versiones
   - AuditorÃ­a de uso

4ï¸âƒ£ ANALYTICS:
   - QuÃ© secciones se consultan mÃ¡s
   - Gaps en documentaciÃ³n
   - Calidad de la base de conocimiento
```

---

## ðŸ† DesafÃ­o 7: Re-ranking Avanzado

**Archivo**: `02_solucion_desafio_reranking.py`
**Dificultad**: â­â­â­ Alta
**Tiempo estimado**: 45-60 minutos

### Objetivo
Implementar sistema de re-ranking multi-seÃ±al para mejorar relevancia de resultados.

### SeÃ±ales de ranking
1. **SemÃ¡ntico** (40%): Score original del embedding
2. **Keywords** (25%): Coincidencia exacta de tÃ©rminos
3. **PosiciÃ³n** (10%): UbicaciÃ³n en el documento
4. **Longitud** (10%): CercanÃ­a a longitud Ã³ptima
5. **Completitud** (15%): Frases completas

### Snippet clave
```python
def rerank_results(query, results, weights=None):
    if weights is None:
        weights = {
            'semantic': 0.40,
            'keyword': 0.25,
            'position': 0.10,
            'length': 0.10,
            'completeness': 0.15
        }

    reranked = []
    for result in results:
        # Calcular scores individuales
        keyword_score = calculate_keyword_score(query, result['text'])
        position_score = calculate_position_score(result['metadata']['chunk_id'])
        length_score = calculate_length_score(len(result['text']))
        completeness_score = calculate_completeness_score(result['text'])

        # Score final ponderado
        final_score = (
            result['score'] * weights['semantic'] +
            keyword_score * weights['keyword'] +
            position_score * weights['position'] +
            length_score * weights['length'] +
            completeness_score * weights['completeness']
        )

        result['rerank_score'] = final_score
        reranked.append(result)

    return sorted(reranked, key=lambda x: x['rerank_score'], reverse=True)
```

### Configuraciones pre-definidas
```python
configs = {
    'balanced': {
        'semantic': 0.40, 'keyword': 0.25, 'position': 0.10,
        'length': 0.10, 'completeness': 0.15
    },
    'keyword_focused': {
        'semantic': 0.30, 'keyword': 0.40, 'position': 0.05,
        'length': 0.10, 'completeness': 0.15
    },
    'quality_focused': {
        'semantic': 0.35, 'keyword': 0.20, 'position': 0.05,
        'length': 0.15, 'completeness': 0.25
    },
}
```

### Mejoras demostradas
```
âœ… Penaliza chunks incompletos o mal formados
âœ… Potencia matches exactos de keywords importantes
âœ… Considera contexto del documento (posiciÃ³n)
âœ… Mejora precision@3 en ~15-20%

Ejemplo:
Chunk incompleto "Seg" con score 0.78
â†’ DespuÃ©s de re-ranking: 0.45 (penalizado por completeness)

Chunk con keyword "senior" y score 0.80
â†’ DespuÃ©s de re-ranking: 0.88 (potenciado por keyword match)
```

---

## ðŸš€ CÃ³mo usar estas soluciones

### Durante el workshop (Participantes)
```bash
# NO mirar las soluciones hasta intentar el ejercicio
# Si te atascas, pregunta al instructor primero

# Si necesitas un hint:
cat solutions/nivel_2_workshop/README_SOLUCIONES.md | grep "Snippet clave" -A 10
```

### Durante el workshop (Instructores)
```bash
# Mostrar solo el snippet relevante, no todo el archivo
# Explicar la lÃ³gica sin dar la soluciÃ³n completa
# Dejar que completen los detalles

# Para desbloquear rÃ¡pido:
python solutions/nivel_2_workshop/02_solucion_ejercicio1.py
```

### Post-workshop (Estudio)
```bash
# Comparar tu soluciÃ³n con la esperada
diff mi_solucion.py solutions/nivel_2_workshop/02_solucion_ejercicio1.py

# Ejecutar todas las soluciones
for file in solutions/nivel_2_workshop/*.py; do
    echo "Ejecutando $file"
    python "$file"
done
```

---

## ðŸ“Š MÃ©tricas de aprendizaje

### Cobertura de conceptos

| Concepto | Ejercicio | Dificultad | Tiempo |
|----------|-----------|------------|--------|
| ExperimentaciÃ³n sistemÃ¡tica | Ej 1 | Media | 20 min |
| Metadata filtering | Ej 2 | Media | 15 min |
| Prompt engineering | Ej 3 | Media | 15 min |
| LLM parameters | Ej 4 | Media | 20 min |
| Text processing avanzado | DesafÃ­o 5 | Alta | 40 min |
| Data enrichment | DesafÃ­o 6 | Alta | 50 min |
| Multi-signal ranking | DesafÃ­o 7 | Alta | 60 min |

**Total tiempo estimado**:
- Ejercicios principales: 70 minutos
- DesafÃ­os adicionales: 150 minutos
- **Total**: 220 minutos (3h 40min)

### ProgresiÃ³n de dificultad
```
â­â­ Media (Ejercicios 1-4)
â†’ Conceptos fundamentales
â†’ ImplementaciÃ³n guiada
â†’ Resultados inmediatos

â­â­â­ Alta (DesafÃ­os 5-7)
â†’ Conceptos avanzados
â†’ ImplementaciÃ³n autÃ³noma
â†’ OptimizaciÃ³n y tuning
```

---

## ðŸ’¡ Tips de aprendizaje

### Para maximizar el aprendizaje:

1. **Intenta primero sin mirar**: El error es parte del aprendizaje
2. **Lee los comentarios**: Explican el "por quÃ©", no solo el "cÃ³mo"
3. **Modifica los parÃ¡metros**: Prueba valores diferentes
4. **Compara con tu soluciÃ³n**: Â¿QuÃ© mejoras puedes adoptar?
5. **Experimenta con tus datos**: Aplica a tu caso de uso real

### Para instructores:

1. **Nivel 1 (Desbloqueo rÃ¡pido)**: Mostrar snippet clave
2. **Nivel 2 (Referencia)**: Ejecutar soluciÃ³n completa
3. **Nivel 3 (ProfundizaciÃ³n)**: Discutir trade-offs y alternativas

---

## ðŸ“š Recursos adicionales

- [DocumentaciÃ³n OpenAI Embeddings](https://platform.openai.com/docs/guides/embeddings)
- [ChromaDB Metadata Filtering](https://docs.trychroma.com/usage-guide#filtering-by-metadata)
- [Best Practices for Prompt Engineering](https://platform.openai.com/docs/guides/prompt-engineering)
- [BM25 Algorithm](https://en.wikipedia.org/wiki/Okapi_BM25)

---

**Ãšltima actualizaciÃ³n**: 2025-10-01
**Autor**: Antonio Romero (aromero@secture.com)
**Workshop**: RAG 2025 - De Cero a ProducciÃ³n
