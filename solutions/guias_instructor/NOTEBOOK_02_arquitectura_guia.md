# üéì Gu√≠a del Instructor - Notebook 02: Arquitectura y Optimizaci√≥n
## Reduciendo Latencia 50% y Mejorando Calidad

---

## üìã Informaci√≥n General

**Duraci√≥n:** 90 minutos (10:45-12:15 con break 12:15-12:30)
- **Teor√≠a:** 45 min (10:45-11:30)
- **Pr√°ctica:** 45 min (11:30-12:15)
- **Break:** 15 min (12:15-12:30)

**Objetivo:** Optimizar el RAG b√°sico para mejorar latencia, costo y calidad
**Nivel:** Intermedio
**Pre-requisitos:** Haber completado M√≥dulo 1 (SimpleRAG funcional)

---

## üéØ Objetivos de Aprendizaje

Al finalizar este m√≥dulo, los participantes ser√°n capaces de:

1. ‚úÖ **Implementar** chunking con overlap para preservar contexto
2. ‚úÖ **Aplicar** caching para queries repetidas (speedup 10x)
3. ‚úÖ **Crear** prompts optimizados y especializados
4. ‚úÖ **Implementar** re-ranking de resultados sem√°nticos
5. ‚úÖ **Optimizar** par√°metros del LLM (temperature, max_tokens)
6. ‚úÖ **Reducir** latencia de 2000ms ‚Üí 1000ms (-50%)
7. ‚úÖ **Mejorar** accuracy de 70% ‚Üí 80% (+10%)

---

## üìä M√©tricas Target

| M√©trica | M√≥dulo 1 (Baseline) | M√≥dulo 2 (Target) | Mejora |
|---------|---------------------|-------------------|---------|
| ‚è±Ô∏è Latencia | 2000ms | 1000ms | -50% |
| üí∞ Costo | $0.010 | $0.008 | -20% |
| üéØ Accuracy | 70% | 80% | +10% |

---

## üóìÔ∏è Timeline Detallado

| Tiempo | Secci√≥n | Actividad | Celdas |
|--------|---------|-----------|--------|
| 10:45-11:00 | Parte 1: Comparaci√≥n | Baseline vs Optimized | 1-5 |
| 11:00-11:30 | Parte 2: Optimizaciones | Cache, Rerank, Metadatos | 6-9 |
| 11:30-11:45 | Parte 3: Prompts | Templates y Temperature | 10-12 |
| 11:45-12:05 | Parte 4: Benchmark | Comparaci√≥n final | 13-15 |
| 12:05-12:15 | Ejercicios | Pr√°ctica guiada | 16-19 |

---

## üìù Gui√≥n de la Sesi√≥n

### PARTE 1: Comparaci√≥n con M√≥dulo 1 [10:45-11:00] - 15 min

#### 1. Setup y Contexto (3 min)

**Instructor presenta:**

> "En M√≥dulo 1 construimos un RAG funcional pero b√°sico. Ahora vamos a optimizarlo profesionalmente. Al final de este m√≥dulo tendr√°n un sistema 2x m√°s r√°pido y 15% m√°s preciso."

**Ejecutar Celda 2:**
```python
from module_1_basics import Module1_BasicRAG
from module_2_optimized import Module2_OptimizedRAG

rag_v1 = Module1_BasicRAG()  # Baseline
rag_v2 = Module2_OptimizedRAG()  # Optimizado
```

**Mostrar configuraciones:**
```
üìä Configuraci√≥n:
M√≥dulo 1: chunk_size=500, overlap=0
M√≥dulo 2: chunk_size=1000, overlap=200
```

**Explicar cambios clave:**
- **Chunk size mayor:** 500 ‚Üí 1000 chars (m√°s contexto por chunk)
- **Overlap:** 0 ‚Üí 200 chars (preserva contexto entre chunks)
- **Cache:** No ‚Üí S√≠ (respuestas instant√°neas para queries repetidas)
- **Re-ranking:** No ‚Üí S√≠ (mejora relevancia)

#### 2. Chunking Mejorado (7 min)

**Instructor ejecuta Celda 4:**

```python
# Cargar mismo documento
doc = rag_v1.load_document()

# Chunking v1 (sin overlap)
chunks_v1 = rag_v1.create_chunks(doc)  # ‚Üí 91 chunks

# Chunking v2 (con overlap)
chunks_v2 = rag_v2.create_chunks(doc)  # ‚Üí 114 chunks
```

**Resultados t√≠picos:**
```
üìä Resultados:
V1 (sin overlap): 91 chunks
V2 (con overlap): 114 chunks (+23 chunks, +25%)
```

**Explicar por qu√© m√°s chunks:**
- Cada chunk de 1000 chars
- Se avanza solo 800 chars (1000-200 overlap)
- Los √∫ltimos 200 chars de cada chunk se repiten en el siguiente
- Esto preserva contexto entre boundaries

**An√°lisis de cobertura:**
```python
test_phrase = "pol√≠tica de vacaciones"
v1_contains = sum(1 for c in chunks_v1 if test_phrase in c.lower())  # ‚Üí 1
v2_contains = sum(1 for c in chunks_v2 if test_phrase in c.lower())  # ‚Üí 2
```

**üí° Insight clave:**
> "Con overlap, frases que ca√≠an en boundaries ahora aparecen completas en 2 chunks. Esto mejora mucho la b√∫squeda sem√°ntica."

**Ejecutar Celda 5 (visualizaci√≥n):**

**Diagrama sin overlap:**
```
[Chunk 1: 0-1000][Chunk 2: 1000-2000][Chunk 3: 2000-3000]
                  ‚Üë Aqu√≠ se pierde contexto
```

**Diagrama con overlap:**
```
[Chunk 1: 0-1000]
     [Chunk 2: 800-1800]
          [Chunk 3: 1600-2600]
  üî¥ = Zonas de overlap (contexto compartido)
```

**Analog√≠a √∫til:**
> "Es como leer un libro con binoculares: siempre mantienes un poco del contenido anterior visible mientras avanzas."

---

### PARTE 2: Optimizaciones Avanzadas [11:00-11:30] - 30 min

#### 3. Indexaci√≥n Optimizada (5 min)

**Instructor ejecuta Celda 7:**

```python
# M√≥dulo 1
start = time.time()
rag_v1.index_chunks(chunks_v1[:20])
v1_time = (time.time() - start) * 1000  # ~1,200ms

# M√≥dulo 2 (con metadatos)
start = time.time()
rag_v2.index_chunks(chunks_v2[:25])
v2_time = (time.time() - start) * 1000  # ~1,400ms
```

**Explicar por qu√© es ligeramente m√°s lento:**
- V2 procesa m√°s chunks (25 vs 20)
- V2 a√±ade metadatos a cada chunk:
  - `chunk_id`: Identificador √∫nico
  - `position`: Posici√≥n en documento
  - `source`: Nombre del documento
  - `timestamp`: Cu√°ndo se index√≥

**Valor de los metadatos:**
```python
# Permitir√° filtrar resultados
results = rag_v2.search_with_metadata(
    query="vacaciones",
    filters={"source": "company_handbook.pdf"}
)
```

#### 4. Caching Inteligente (8 min) ‚≠ê CORE FEATURE

**Instructor ejecuta Celda 8:**

```python
query_test = "¬øCu√°l es la pol√≠tica de vacaciones?"

# Primera ejecuci√≥n (sin cache)
result1 = rag_v2.query(query_test)
time1 = result1['metrics']['total_time_ms']  # ~1,800ms

# Segunda ejecuci√≥n (CON cache)
result2 = rag_v2.query(query_test)
time2 = result2['metrics']['total_time_ms']  # ~150ms
```

**Resultados esperados:**
```
üìä Mejora por cache:
Sin cache: 1,823ms
Con cache: 147ms
Speedup: 12.4x m√°s r√°pido
Ahorro: 1,676ms
```

**Explicar c√≥mo funciona el cache:**

```python
# Pseudo-c√≥digo del cache
def query(self, question):
    cache_key = hashlib.md5(question.encode()).hexdigest()

    # Revisar cache
    if cache_key in self.cache:
        return self.cache[cache_key]  # Instant√°neo!

    # Si no est√° en cache, procesar normal
    result = self._process_query(question)

    # Guardar en cache
    self.cache[cache_key] = result
    return result
```

**Casos de uso del cache:**
- Preguntas frecuentes (FAQ)
- Dashboards que refrescan cada minuto
- Queries de m√∫ltiples usuarios (misma pregunta)

**Limitaciones del cache:**
- Solo funciona para queries EXACTAMENTE iguales
- Requiere memoria (en producci√≥n usar Redis)
- Cache puede desactualizarse si cambias documentos

**üí° Pr√°ctica:**
> "Probemos con una variaci√≥n de la query..."

```python
# Query ligeramente diferente
result3 = rag_v2.query("¬øCu√°l es la pol√≠tica de vacaciones?")  # Sin ? final
# ‚Üí NO usa cache (string diferente)
```

**Soluci√≥n avanzada (mencionar brevemente):**
```python
# Normalizar queries antes de cachear
def normalize_query(q):
    return q.lower().strip().rstrip('?!.')

cache_key = hashlib.md5(normalize_query(question).encode()).hexdigest()
```

#### 5. Re-ranking Sem√°ntico (10 min) ‚≠ê CORE FEATURE

**Instructor ejecuta Celda 9:**

```python
query = "beneficios para empleados senior"

# Sin re-ranking (v1)
results_v1 = rag_v1.search(query, k=5)

# Con re-ranking (v2)
results_v2 = rag_v2.search_with_rerank(query, k=5)
```

**Comparar resultados:**

**Sin re-ranking:**
```
Chunk 1: "...beneficios incluyen seguro m√©dico, dental y visi√≥n..."
Chunk 2: "...empleados senior con m√°s de 5 a√±os tienen acceso..."
Chunk 3: "...la cafeter√≠a ofrece descuentos para empleados..."
```

**Con re-ranking:**
```
Chunk 1: "...empleados senior con m√°s de 5 a√±os tienen acceso..." (Score: 0.892)
Chunk 2: "...beneficios adicionales para senior: bonos anuales..." (Score: 0.845)
Chunk 3: "...beneficios incluyen seguro m√©dico, dental y visi√≥n..." (Score: 0.723)
```

**Explicar algoritmo de re-ranking:**

```python
def rerank_results(query, results, weights=None):
    """
    Combina m√∫ltiples se√±ales:
    1. Similitud sem√°ntica (embedding similarity) - 40%
    2. Keyword matching (BM25-like) - 25%
    3. Position bias (chunks tempranos) - 10%
    4. Length preference (chunks completos) - 10%
    5. Metadata signals (relevancia de secci√≥n) - 15%
    """

    scores = []
    for doc in results:
        # Se√±al 1: Embedding similarity (ya calculado)
        semantic_score = doc['distance']

        # Se√±al 2: Keyword matching
        keywords = extract_keywords(query)
        keyword_score = sum(1 for kw in keywords if kw in doc['text']) / len(keywords)

        # Se√±al 3: Position (primeros chunks son m√°s importantes)
        position_score = 1 / (1 + doc['position'] / 10)

        # Se√±al 4: Length (preferir chunks completos)
        length_score = min(len(doc['text']) / 1000, 1.0)

        # Se√±al 5: Metadata (ejemplo: secci√≥n "benefits" m√°s relevante)
        metadata_score = 1.0 if doc.get('section') == 'benefits' else 0.5

        # Score final ponderado
        final_score = (
            semantic_score * 0.40 +
            keyword_score * 0.25 +
            position_score * 0.10 +
            length_score * 0.10 +
            metadata_score * 0.15
        )

        scores.append(final_score)

    # Re-ordenar por score
    sorted_results = sorted(zip(results, scores), key=lambda x: x[1], reverse=True)
    return sorted_results
```

**üí° Valor del re-ranking:**
- Mejora precisi√≥n 15-20%
- Especialmente √∫til cuando embedding similarity no es suficiente
- Combina lo mejor de b√∫squeda sem√°ntica + keyword

**Cu√°ndo NO usar re-ranking:**
- Si latencia es cr√≠tica (a√±ade ~100-200ms)
- Si los resultados de embedding ya son muy buenos
- Si no tienes suficientes se√±ales adicionales

#### 6. Metadatos Enriquecidos (7 min)

**Mostrar ejemplo de chunk con metadatos:**

```python
{
    'id': 'chunk_42',
    'text': 'Los empleados senior con m√°s de 5 a√±os...',
    'metadata': {
        'source': 'company_handbook.pdf',
        'page': 15,
        'section': 'benefits',
        'subsection': 'senior_benefits',
        'chunk_position': 42,
        'char_count': 987,
        'word_count': 156,
        'has_numbers': True,
        'has_lists': True,
        'created_at': '2025-01-15T10:30:00Z',
        'hash': 'a3f2b8c...'
    }
}
```

**Usos de metadatos:**

1. **Filtrado:**
```python
# Solo chunks de la secci√≥n de beneficios
results = collection.query(
    query_texts=["vacaciones"],
    where={"section": "benefits"}
)
```

2. **Citaci√≥n de fuentes:**
```python
# Incluir en la respuesta
answer = f"{response}\n\nFuente: {metadata['source']}, p√°gina {metadata['page']}"
```

3. **Deduplicaci√≥n:**
```python
# Evitar chunks duplicados por overlap
seen_hashes = set()
unique_results = [r for r in results if r['hash'] not in seen_hashes and not seen_hashes.add(r['hash'])]
```

4. **Analytics:**
```python
# Qu√© secciones se consultan m√°s
section_stats = Counter(r['metadata']['section'] for r in all_queries)
```

---

### PARTE 3: Optimizaci√≥n de Prompts [11:30-11:45] - 15 min

#### 7. Comparar Prompts (7 min)

**Instructor ejecuta Celda 11:**

**Prompt b√°sico (M√≥dulo 1):**
```python
prompt_v1 = """
Contexto: {context}
Pregunta: {question}
Responde bas√°ndote en el contexto.
"""
# 76 tokens
```

**Prompt optimizado (M√≥dulo 2):**
```python
prompt_v2 = """
Eres un asistente experto en recursos humanos analizando documentos de la empresa.

CONTEXTO RELEVANTE:
{context}

PREGUNTA DEL EMPLEADO:
{question}

INSTRUCCIONES:
1. Responde √öNICAMENTE bas√°ndote en el contexto proporcionado
2. Si la informaci√≥n est√° incompleta, ind√≠calo claramente
3. Usa bullet points para listas
4. S√© espec√≠fico con n√∫meros y fechas
5. M√°ximo 3-4 oraciones para respuestas simples

RESPUESTA:
"""
# 142 tokens
```

**Diferencias clave:**

| Aspecto | Prompt B√°sico | Prompt Optimizado |
|---------|--------------|-------------------|
| **Rol** | No definido | "Asistente experto en RH" |
| **Estructura** | Plana | Secciones claras (CONTEXTO, PREGUNTA, INSTRUCCIONES) |
| **Restricciones** | Vago ("bas√°ndote en contexto") | Espec√≠fico ("√öNICAMENTE", "m√°ximo 3-4 oraciones") |
| **Formato** | No especificado | "Bullet points para listas" |
| **Manejo de edge cases** | No contempla | "Si info incompleta, ind√≠calo" |
| **Tokens** | 76 | 142 (+87% m√°s largo) |

**‚ö†Ô∏è Trade-off importante:**
- Prompt m√°s largo = m√°s tokens = m√°s costo
- Pero mejora calidad significativamente
- En este caso: +87% tokens, pero +15% accuracy ‚Üí Vale la pena

**Mostrar resultados comparativos:**

```python
# Misma query con ambos prompts
query = "¬øCu√°l es la pol√≠tica de trabajo remoto?"

# Con prompt b√°sico
"La empresa permite trabajo remoto 2 d√≠as a la semana."

# Con prompt optimizado
"Pol√≠tica de Trabajo Remoto:
‚Ä¢ Empleados pueden trabajar remotamente hasta 2 d√≠as/semana
‚Ä¢ Requiere aprobaci√≥n previa del manager
‚Ä¢ Debe mantener disponibilidad en horario laboral (9 AM - 6 PM)

Nota: Esta pol√≠tica aplica solo para roles elegibles (ver manual, p√°g. 23)"
```

**Mejor estructura, m√°s detalle, incluye source.**

#### 8. Experimentar con Temperature (8 min)

**Instructor ejecuta Celda 12:**

```python
query = "¬øCu√°les son los beneficios de la empresa?"
temperatures = [0.0, 0.3, 0.7, 1.0]

for temp in temperatures:
    rag_v2.temperature = temp
    result = rag_v2.query(query)
    print(f"üå°Ô∏è Temp {temp}: {result['response'][:150]}...")
```

**Resultados esperados:**

**Temperature 0.0 (Determin√≠stico):**
```
Los beneficios incluyen:
- Seguro m√©dico, dental y de visi√≥n
- 401(k) con 4% de matching
- 22 d√≠as de vacaciones
- Licencia parental pagada
```
*Siempre la misma respuesta, palabra por palabra*

**Temperature 0.3 (Recomendado):**
```
La empresa ofrece los siguientes beneficios:
‚Ä¢ Cobertura m√©dica completa (salud, dental, visi√≥n)
‚Ä¢ Plan de retiro 401(k) con aporte de 4%
‚Ä¢ 22 d√≠as h√°biles de vacaciones anuales
‚Ä¢ Licencia parental de 12 semanas pagadas
```
*Ligeramente diferente cada vez, pero consistente en contenido*

**Temperature 0.7 (Creativo):**
```
¬°Tenemos excelentes beneficios! Destacan nuestro robusto seguro m√©dico
que cubre todo, un generoso 401(k) donde la empresa aporta hasta 4%,
vacaciones abundantes (22 d√≠as!), y una pol√≠tica parental l√≠der en la industria.
```
*M√°s variaci√≥n, tono m√°s conversacional*

**Temperature 1.0 (Muy creativo):**
```
Nuestro paquete de beneficios es excepcional. Imagina tener tranquilidad
total con seguro m√©dico premium, construir tu futuro con 401(k) generoso,
disfrutar de casi un mes de vacaciones, y adem√°s...
```
*Mucha variaci√≥n, puede divagar*

**Tabla comparativa:**

| Temperature | Variaci√≥n | Tono | Adherencia al Contexto | Recomendado Para |
|-------------|-----------|------|------------------------|------------------|
| 0.0 | Ninguna | Rob√≥tico | 100% | Respuestas t√©cnicas exactas |
| 0.3 | M√≠nima | Natural | 98% | **RAG general (√ìPTIMO)** |
| 0.7 | Media | Conversacional | 90% | Chatbots creativos |
| 1.0 | Alta | Muy libre | 75% | Escritura creativa |

**üí° Recomendaci√≥n:**
> "Para RAG, temperature 0.3 es el sweet spot. Suficiente variaci√≥n para sonar natural, pero muy adherente al contexto. Temperature alta (0.7-1.0) aumenta riesgo de alucinaciones."

---

### PARTE 4: M√©tricas y Comparaci√≥n Final [11:45-12:05] - 20 min

#### 9. Benchmark Completo (12 min)

**Instructor ejecuta Celda 14:**

```python
test_queries = [
    "¬øCu√°l es la pol√≠tica de vacaciones?",
    "¬øQu√© beneficios tienen los empleados senior?",
    "¬øC√≥mo funciona el trabajo remoto?",
    "¬øCu√°l es el proceso de onboarding?"
]

results_comparison = []

for query in test_queries:
    # M√≥dulo 1
    result_v1 = rag_v1.query(query)
    time_v1 = ...
    eval_v1 = TestSuite.evaluate_response(result_v1, Module.BASICS)

    # M√≥dulo 2
    result_v2 = rag_v2.query(query)
    time_v2 = ...
    eval_v2 = TestSuite.evaluate_response(result_v2, Module.OPTIMIZED)

    results_comparison.append({...})
```

**Resultados t√≠picos:**

| Query | V1 Time | V2 Time | V1 Score | V2 Score | Speedup |
|-------|---------|---------|----------|----------|---------|
| Pol√≠tica vacaciones | 1,923ms | 1,045ms | 0.72 | 0.85 | 1.84x |
| Beneficios senior | 2,134ms | 987ms | 0.68 | 0.82 | 2.16x |
| Trabajo remoto | 1,845ms | 1,123ms | 0.75 | 0.88 | 1.64x |
| Proceso onboarding | 2,087ms | 1,234ms | 0.71 | 0.79 | 1.69x |
| **PROMEDIO** | **1,997ms** | **1,097ms** | **0.72** | **0.84** | **1.83x** |

**An√°lisis de mejoras:**
```
üìà MEJORAS PROMEDIO:
‚è±Ô∏è Latencia: 1,997ms ‚Üí 1,097ms (1.8x m√°s r√°pido, -45%)
üéØ Calidad: 0.72 ‚Üí 0.84 (+0.12, +17%)
```

**‚≠ê Cumplimos targets:**
- ‚úÖ Latencia: Target era 1,000ms, logramos 1,097ms (muy cerca)
- ‚úÖ Calidad: Target era 0.80, logramos 0.84 (superado)

#### 10. Visualizar Mejoras (8 min)

**Instructor ejecuta Celda 15 (gr√°ficos):**

**Gr√°fico 1: Reducci√≥n de Latencia**
- Barras: M√≥dulo 1 (rojo) vs M√≥dulo 2 (verde)
- Flecha verde mostrando mejora de -45%
- L√≠nea de objetivo (1,000ms)

**Gr√°fico 2: Mejora en Calidad**
- Barras mostrando score 0.72 ‚Üí 0.84
- Destacar que superamos el target de 0.80

**Gr√°fico 3: Breakdown de Tiempos**
- M√≥dulo 1: Retrieval (800ms) + Generation (1,200ms) + Cache (0ms)
- M√≥dulo 2: Retrieval (600ms) + Generation (400ms) + Cache (50ms) + Rerank (50ms)

**Explicar cada optimizaci√≥n:**

```
üìä Breakdown de optimizaciones:

Retrieval: 800ms ‚Üí 600ms (-200ms)
  ‚Ä¢ Chunks m√°s grandes = menos chunks = menos b√∫squedas

Generation: 1,200ms ‚Üí 400ms (-800ms) üèÜ MAYOR MEJORA
  ‚Ä¢ Cache hits ahorran 90% del tiempo
  ‚Ä¢ Prompt optimizado genera respuestas m√°s concisas

Nuevos componentes:
  ‚Ä¢ Cache lookup: +50ms (pero ahorra 1,200ms cuando hit)
  ‚Ä¢ Re-ranking: +50ms (pero mejora accuracy 15%)
```

**üí° Lecci√≥n clave:**
> "El cache es el componente con mayor ROI. Un cache hit ahorra 1,200ms y solo cuesta 50ms de lookup. Por eso en producci√≥n siempre usen cache (Redis, Memcached)."

---

### PARTE 5: Ejercicios Pr√°cticos [12:05-12:15] - 10 min

**Instructor presenta los 3 ejercicios (Celdas 17-19):**

#### Ejercicio 1: Optimizar chunk_size (3 min)

**Instructor explica:**
> "Probamos 500 y 1000. ¬øCu√°l es el tama√±o √≥ptimo? Experimenten con [300, 500, 800, 1000, 1500, 2000]"

**Estructura sugerida:**
```python
chunk_sizes = [300, 500, 800, 1000, 1500, 2000]
results = []

for size in chunk_sizes:
    rag_v2.chunk_size = size
    chunks = rag_v2.create_chunks(doc)
    rag_v2.index_chunks(chunks[:30])

    result = rag_v2.query("¬øCu√°l es la pol√≠tica de vacaciones?")
    results.append({
        'size': size,
        'latency': result['metrics']['total_time_ms'],
        'quality': TestSuite.evaluate_response(result['response'], Module.OPTIMIZED)['score']
    })

# Graficar latencia vs quality
```

**Respuesta esperada:**
- Chunks muy peque√±os (300): Muchos chunks, slow retrieval, contexto fragmentado
- **Chunks medianos (800-1000): Balance √≥ptimo** ‚≠ê
- Chunks muy grandes (2000): Pocos chunks, contexto diluido

#### Ejercicio 2: Filtrado por Metadatos (3 min)

**Instructor explica:**
> "Implementen una funci√≥n que filtre resultados por secci√≥n del documento"

**Soluci√≥n b√°sica:**
```python
def filter_by_metadata(results, filter_criteria):
    filtered = []
    for result in results:
        match = True
        for key, value in filter_criteria.items():
            if result['metadata'].get(key) != value:
                match = False
                break
        if match:
            filtered.append(result)
    return filtered

# Uso
filter_criteria = {"section": "benefits"}
filtered_results = filter_by_metadata(results, filter_criteria)
```

#### Ejercicio 3: Prompt T√©cnico Especializado (4 min)

**Instructor muestra ejemplo:**

```python
technical_prompt = """
Eres un especialista en soporte t√©cnico IT analizando documentaci√≥n t√©cnica corporativa.

DOCUMENTACI√ìN RELEVANTE:
{context}

CONSULTA T√âCNICA:
{question}

INSTRUCCIONES:
1. Proporciona SOLO informaci√≥n basada en la documentaci√≥n
2. Si requiere configuraci√≥n, usa formato de c√≥digo:
   ```
   par√°metro: valor
   ```
3. Incluye advertencias de seguridad si aplica
4. Si la info est√° incompleta, indica claramente qu√© falta
5. Estructura la respuesta as√≠:
   - Respuesta directa (1-2 l√≠neas)
   - Pasos de configuraci√≥n (si aplica)
   - Notas adicionales

RESPUESTA T√âCNICA:
"""

# Probar con query t√©cnica
rag_v2.prompt_template = technical_prompt
result = rag_v2.query("¬øC√≥mo configuro el VPN de la empresa?")
```

**Salida esperada:**
```
Para configurar el VPN corporativo:

PASOS:
1. Descarga el cliente Cisco AnyConnect desde el portal IT
2. Configuraci√≥n:
   ```
   Server: vpn.techcorp.com
   Port: 443
   Protocol: SSL
   ```
3. Credenciales: Usa tu usuario corporativo + token MFA

‚ö†Ô∏è SEGURIDAD: Nunca uses VPN desde redes p√∫blicas sin verificar el certificado SSL primero.

Nota: Para troubleshooting, contacta IT Help Desk (ext. 5500).
```

**Comparar con prompt gen√©rico** para mostrar la diferencia.

---

## üéâ Cierre del M√≥dulo [12:10-12:15] - 5 min

**Instructor ejecuta Celda 20 y resume:**

### ‚úÖ Lo que lograron:

1. **Chunking con Overlap** ‚Üí Mejor preservaci√≥n de contexto (+25% cobertura)
2. **Caching Inteligente** ‚Üí Respuestas instant√°neas (12x speedup)
3. **Re-ranking** ‚Üí Resultados m√°s relevantes (+15% accuracy)
4. **Prompts Optimizados** ‚Üí Respuestas m√°s precisas y estructuradas
5. **Metadatos Enriquecidos** ‚Üí Mejor trazabilidad y filtrado

### üìä Mejoras Conseguidas:

| M√©trica | M√≥dulo 1 | M√≥dulo 2 | Mejora | Target |
|---------|----------|----------|--------|--------|
| Latencia | 2000ms | 1100ms | **-45%** | -50% ‚úÖ |
| Costo | $0.010 | $0.008 | **-20%** | -20% ‚úÖ |
| Calidad | 0.70 | 0.84 | **+20%** | +10% ‚úÖ‚úÖ |

**Superamos todos los targets!**

### üöÄ Pr√≥ximo: M√≥dulo 3 - Frameworks Avanzados

**Instructor explica:**
> "Hasta ahora hemos construido todo desde cero para entender los fundamentos. En M√≥dulo 3 usaremos frameworks profesionales:
> - **LangChain:** Para pipelines complejos y agents
> - **LlamaIndex:** Para indexaci√≥n avanzada y multi-document
> - **LangGraph:** Para workflows con estado
> - **Evaluaci√≥n:** Para medir calidad objetivamente"

**Transici√≥n:**
> "¬°Break de 15 minutos! Nos vemos en el M√≥dulo 3 a las 12:30\. Aprovechen para:
> - Experimentar con los ejercicios
> - Revisar las soluciones en `/solutions/nivel_2_workshop/`
> - Pensar en su caso de uso espec√≠fico"

---

## üìä M√©tricas de √âxito del M√≥dulo

Al final del m√≥dulo, verificar:

- [ ] **90%+** implementaron chunking con overlap exitosamente
- [ ] **90%+** vieron mejora de latencia con cache
- [ ] **80%+** entienden c√≥mo funciona re-ranking
- [ ] **100%** ejecutaron benchmark comparativo
- [ ] **Promedio grupal:** Latencia < 1,200ms
- [ ] **Promedio grupal:** Accuracy > 0.78
- [ ] **Al menos 50%** intentaron los ejercicios pr√°cticos

---

## üö® Problemas Comunes y Soluciones

### 1. Cache no funciona
**S√≠ntomas:** Segunda query tarda igual que la primera
**Causas:**
- Query con diferente capitalizaci√≥n
- Espacio extra al inicio/final
- Signos de puntuaci√≥n diferentes

**Soluci√≥n:**
```python
# Verificar que las queries son id√©nticas
q1 = "¬øCu√°l es la pol√≠tica de vacaciones?"
q2 = "¬øCu√°l es la pol√≠tica de vacaciones?"
print(q1 == q2)  # Debe ser True

# Si no funciona, revisar implementaci√≥n del cache
print(rag_v2.cache.keys())  # Ver qu√© queries est√°n cacheadas
```

### 2. Overlap genera chunks duplicados en resultados
**S√≠ntomas:** Misma informaci√≥n aparece 2-3 veces en la respuesta
**Causa:** Chunks solapados son muy similares

**Soluci√≥n:**
```python
# Deduplicaci√≥n por hash
def deduplicate_results(results):
    seen_hashes = set()
    unique = []
    for r in results:
        content_hash = hashlib.md5(r['text'].encode()).hexdigest()
        if content_hash not in seen_hashes:
            unique.append(r)
            seen_hashes.add(content_hash)
    return unique
```

### 3. Re-ranking empeora resultados
**S√≠ntomas:** Score baja en vez de subir
**Causa:** Pesos mal balanceados

**Soluci√≥n:**
```python
# Experimentar con diferentes pesos
weights = {
    'semantic': 0.60,  # Aumentar si embeddings son buenos
    'keyword': 0.20,   # Reducir si muchos false positives
    'position': 0.05,
    'length': 0.05,
    'metadata': 0.10
}

results = rag_v2.search_with_rerank(query, weights=weights)
```

### 4. Latencia no mejora
**S√≠ntomas:** M√≥dulo 2 igual de lento que M√≥dulo 1
**Causas:**
- Cache deshabilitado
- Queries siempre diferentes (no hits de cache)
- Chunks muy grandes

**Debug:**
```python
# Verificar cache
print(f"Cache enabled: {rag_v2.cache_enabled}")
print(f"Cache size: {len(rag_v2.cache)}")
print(f"Cache hit rate: {rag_v2.cache_hits / (rag_v2.cache_hits + rag_v2.cache_misses)}")

# Verificar tama√±o de chunks
print(f"Average chunk size: {np.mean([len(c) for c in chunks_v2])}")
```

### 5. Prompts optimizados son demasiado caros
**S√≠ntomas:** Costo se dispara por prompts largos
**Soluci√≥n:**
```python
# Prompt medio: m√°s corto que optimizado, mejor que b√°sico
prompt_medium = """
Eres un asistente de RH. Usa SOLO el contexto para responder.

CONTEXTO: {context}
PREGUNTA: {question}

Respuesta concisa con bullets si aplica:
"""
# ~60 tokens (vs 142 del optimizado, 76 del b√°sico)
```

---

## üí° Tips de Ense√±anza

### Timing Cr√≠tico
- **No extender m√°s de 90 min:** El m√≥dulo es denso
- **Almuerzo a tiempo:** Participantes necesitan el break
- **Si van atrasados:** Saltear ejercicios, dejarlos para despu√©s del almuerzo

### Demos Efectivas
- **Cache:** Hacer la demo en vivo, mostrar la diferencia de tiempo
- **Re-ranking:** Mostrar side-by-side con y sin re-ranking
- **Temperature:** Ejecutar m√∫ltiples veces con temp=1.0 para mostrar variaci√≥n

### Engagement
- **Celebrar mejoras:** "¬°Miren, 45% m√°s r√°pido!"
- **Competencia amistosa:** "¬øQui√©n logr√≥ mayor speedup?"
- **Casos reales:** Pedir a participantes que piensen c√≥mo aplicar√≠an cache en su contexto

### Ejercicios
- **No esperar que todos terminen:** 10 min es poco, es exploraci√≥n inicial
- **Soluciones disponibles:** Recordar que est√°n en `/solutions/nivel_2_workshop/`
- **Para casa:** Si no terminan, pueden continuar despu√©s

---

## üìö Recursos Adicionales

### Compartir con participantes:
- [Chunking Strategies Deep Dive](https://www.pinecone.io/learn/chunking-strategies/)
- [Redis for Caching](https://redis.io/docs/manual/client-side-caching/)
- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- Soluciones completas: `/solutions/nivel_2_workshop/`

### Lecturas avanzadas (post-workshop):
- [Hybrid Search (Dense + Sparse)](https://www.pinecone.io/learn/hybrid-search/)
- [Re-ranking Algorithms](https://www.sbert.net/examples/applications/cross-encoder/README.html)
- [Production RAG Patterns](https://eugeneyan.com/writing/llm-patterns/)

---

## ‚úÖ Checklist del Instructor

**Antes del m√≥dulo:**
- [ ] Revisar soluciones en `/solutions/nivel_2_workshop/`
- [ ] Probar benchmark comparativo con datos reales
- [ ] Preparar ejemplos de prompts especializados
- [ ] Tener gr√°ficos de mejoras listos

**Durante el m√≥dulo:**
- [ ] Demo de cache en vivo (Celda 8)
- [ ] Mostrar re-ranking side-by-side (Celda 9)
- [ ] Ejecutar benchmark completo (Celda 14)
- [ ] Mostrar visualizaciones (Celda 15)
- [ ] Presentar los 3 ejercicios (Celdas 17-19)

**Despu√©s del m√≥dulo:**
- [ ] Recopilar m√©tricas grupales (latencia, accuracy promedio)
- [ ] Identificar optimizaciones que generaron m√°s impacto
- [ ] Anotar preguntas frecuentes para pr√≥ximas ediciones
- [ ] Verificar que participantes tienen acceso a soluciones

---

**üöÄ ¬°√âxito con el m√≥dulo m√°s t√©cnico del d√≠a!**
